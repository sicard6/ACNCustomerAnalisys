{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import selenium as sel\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "import base as bs\n",
    "\n",
    "import os as os\n",
    "import csv\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empresa con la cual vamos a extraer los articulos\n",
    "# TODO Tener una lista que itere por todos lo clientes\n",
    "empresa = input(\"Digite la empresa a extraer: \").lower().strip()\n",
    "if \" \" in empresa:\n",
    "    empresa = empresa.replace(\" \", \"%20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cerar driver... MODIFICAR DEPENDIENDO DEL NAVEGADOR\n",
    "driver = sel.webdriver.Edge()\n",
    "driver.get(f'https://www.semana.com/buscador/?query={empresa}')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrae la lista de todos los articulos de la pagina\n",
    "articulos = driver.find_elements(By.XPATH,'.//div[contains(@class,\"queryly_item_row\")]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itera por cada articulo y extrae la informacion (EN CASO DE QUE NO EXISTA ARCHIVO DE ALMACENAMIENTO ANTERIOR)\n",
    "titulares = []\n",
    "for art in articulos:\n",
    "    url = art.find_element(By.XPATH,'.//a').get_attribute('href')\n",
    "    if not(bs.existedb(url, \"semana\")):\n",
    "        fechaP = art.find_element(By.XPATH,'.//div[contains(@style,\"margin-bottom:0px;color:#555;font-size:12px;\")]').text\n",
    "        resumen = art.find_element(By.XPATH,'.//div[contains(@class,\"queryly_item_description\")]').text\n",
    "        titulo = art.find_element(By.XPATH,'.//div[contains(@class,\"queryly_item_title\")]').text\n",
    "        txtImage = art.find_element(By.XPATH,'.//div[contains(@class,\"queryly_advanced_item_imagecontainer\")]').get_attribute('style')\n",
    "        imagen = 'https://www.semana.com'\n",
    "        imagen = imagen + txtImage.split(\"\\\"\")[1]\n",
    "        titulares.append({'Fecha Extraccion':datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        'Titulo':titulo,\n",
    "                        'Fecha Publicacion':fechaP,\n",
    "                        'Resumen':resumen,\n",
    "                        'URL':url,\n",
    "                        'Imagen':imagen,\n",
    "                        'Empresa':empresa})\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itera por cada articulo y extrae la informacion (CASO DE QUE YA EXISTA ARCHIVO DONDE SE ALMACENA)\n",
    "titulares = []\n",
    "for art in articulos:\n",
    "    url = art.find_element(By.XPATH,'.//a').get_attribute('href')\n",
    "    if not(bs.existedb(url, \"database\")):\n",
    "        fechaP = art.find_element(By.XPATH,'.//div[contains(@style,\"margin-bottom:0px;color:#555;font-size:12px;\")]').text\n",
    "        resumen = art.find_element(By.XPATH,'.//div[contains(@class,\"queryly_item_description\")]').text\n",
    "        titulo = art.find_element(By.XPATH,'.//div[contains(@class,\"queryly_item_title\")]').text\n",
    "        txtImage = art.find_element(By.XPATH,'.//div[contains(@class,\"queryly_advanced_item_imagecontainer\")]').get_attribute('style')\n",
    "        imagen = 'https://www.semana.com'\n",
    "        imagen = imagen + txtImage.split(\"\\\"\")[1]\n",
    "        titulares.append({'Fecha Extraccion':datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        'Titulo':titulo,\n",
    "                        'Fecha Publicacion':fechaP,\n",
    "                        'Resumen':resumen,\n",
    "                        'URL':url,\n",
    "                        'Imagen':imagen,\n",
    "                        'Empresa':empresa})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# busca los autores de cada articulo y las almacena en la lista de titulares\n",
    "for tit in titulares:\n",
    "    \n",
    "    driver.get(tit['URL'])\n",
    "\n",
    "    # agregar contenido al dict de titulares\n",
    "    tit['Contenido'] = bs.obtener_contenido(driver)\n",
    "\n",
    "    # agregar tags al dict de titulares\n",
    "    tit['Tags'] = bs.obtener_tags(driver)\n",
    "    \n",
    "    # agregar contenido al dict de titulares\n",
    "    tit['Tema'] = bs.obtener_tema(driver)\n",
    "    \n",
    "    # agregar fuente al dict de titulares\n",
    "    tit['Fuente'] = 'Semana'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(titulares)\n",
    "bs.writeData(\"database\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
