{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import selenium as sel\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import base as bs\n",
    "\n",
    "import os as os\n",
    "import csv\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titulo(url):\n",
    "    try:\n",
    "        titulo = url.find_elements(By.XPATH,'./a')[0].text\n",
    "    except:\n",
    "        return None\n",
    "    else:\n",
    "        return titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autor(url):\n",
    "    try:\n",
    "        autor = url.find_element(By.XPATH, './/a[contains(@class, \"c_a_a\")]').text\n",
    "    except:\n",
    "        autor = 'SIN AUTOR'\n",
    "    return autor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ciudad(url):\n",
    "    try:\n",
    "        ciudad = url.find_element(By.XPATH, './/span[contains(@class, \"c_a_l\")]').text\n",
    "    except:\n",
    "        ciudad = 'SIN CIUDAD DE PUBLICACION'\n",
    "    return ciudad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fecha(url):\n",
    "    try:\n",
    "        fecha = url.find_element(By.XPATH, './/time').text.split()[:3]\n",
    "        fecha_pub = \" \".join(fecha)\n",
    "    except:\n",
    "        fecha_pub = 'SIN FECHA DE PUBLICACION'\n",
    "    return fecha_pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resumen(url):\n",
    "    try:\n",
    "        resumen = url.find_element(By.XPATH, './/p').text\n",
    "    except:\n",
    "        resumen = 'SIN RESUMEN'\n",
    "    return resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empresa con la cual vamos a extraer los articulos\n",
    "empresa = input(\"Digite la empresa a extraer: \")\n",
    "revista = \"elPais\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear driver... MODIFICAR DEPENDIENDO DEL NAVEGADOR\n",
    "driver = sel.webdriver.Edge()\n",
    "driver.get(f'https://elpais.com/noticias/{empresa}')\n",
    "time.sleep(2)\n",
    "\n",
    "# Si en 5 segundo no ha encontrado el elemento que se le pasa se detiene\n",
    "# Luego acepta los cookies\n",
    "WebDriverWait(driver, 5)\\\n",
    "    .until(EC.element_to_be_clickable((By.CSS_SELECTOR,\n",
    "                                      \"button.didomi-components-button didomi-button didomi-dismiss-button didomi-components-button--color didomi-button-highlight highlight-button\".replace(\" \", \".\"))))\\\n",
    "                                          .click()\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacar primer titular CON BASE DE DATOS INICIAL\n",
    "titulares = []\n",
    "princip = driver.find_element(By.XPATH,'.//h2[contains(@class,\"c_t \")]')\n",
    "urlPrinc = princip.find_elements(By.XPATH,'./a')[0].get_attribute('href')\n",
    "infPrinc = driver.find_element(By.XPATH,'.//div[contains(@class,\"c_a\")]')\n",
    "aux = driver.find_element(By.XPATH,'.//article[contains(@class,\"c c-d c--m   \")]')\n",
    "if not(bs.existedb(urlPrinc, revista)):\n",
    "    tituloPrinc = get_titulo(princip)\n",
    "    autorPrinc = get_autor(infPrinc)\n",
    "    ciudadPrinc = get_ciudad(infPrinc)\n",
    "    fechaPrinc = get_fecha(infPrinc)\n",
    "    resumenPrinc = get_resumen(aux)\n",
    "    titulares.append({'Fecha Extraccion':datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                      'Titulo': tituloPrinc,\n",
    "                      'Fecha Publicacion':fechaPrinc,\n",
    "                      'URL': urlPrinc,\n",
    "                      'Resumen': resumenPrinc,\n",
    "                      'Autor': autorPrinc,\n",
    "                      'Ciudad Publicacion': ciudadPrinc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulos = driver.find_elements(By.XPATH, './/article[contains(@class, \"c c-d c--m   \")]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulares = []\n",
    "for art in articulos:\n",
    "    aux = art.find_element(By.XPATH, './/h2[contains(@class, \"c_t \")]')\n",
    "    url = aux.find_elements(By.XPATH,'./a')[0].get_attribute('href')\n",
    "    if not(bs.existedb(url, revista)):\n",
    "        inf = art.find_element(By.XPATH,'.//div[contains(@class,\"c_a\")]')\n",
    "        titulo = get_titulo(aux)\n",
    "        autor = get_autor(inf)\n",
    "        ciudad = get_ciudad(inf)\n",
    "        fecha = get_fecha(inf)\n",
    "        resumen = get_resumen(art)\n",
    "        titulares.append({'Fecha Extraccion':datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        'Titulo': titulo,\n",
    "                        'Fecha Publicacion':fecha,\n",
    "                        'URL': url,\n",
    "                        'Resumen': resumen,\n",
    "                        'Autor': autor,\n",
    "                        'Ciudad Publicacion': ciudad})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['Fecha Extraccion', 'Titulo', 'Fecha Publicacion', 'URL', 'Resumen',\n",
    "       'Autor', 'Ciudad Publicacion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Fecha Extraccion', 'Titulo', 'Fecha Publicacion', 'URL', 'Resumen',\n",
       "       'Autor', 'Ciudad Publicacion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para AGREGAR titulares a un archivo.\n",
    "with open(f'../data/raw/{revista}.csv', 'a', newline='', errors='ignore') as csv_file:\n",
    "    dict_object = csv.DictWriter(csv_file, fieldnames=columnas) \n",
    "  \n",
    "    dict_object.writerows(titulares)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
