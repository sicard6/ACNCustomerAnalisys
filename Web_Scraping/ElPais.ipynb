{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import selenium as sel\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import base as bs\n",
    "\n",
    "import os as os\n",
    "import csv\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titulo(url):\n",
    "    try:\n",
    "        titulo = url.find_elements(By.XPATH,'./a')[0].text\n",
    "    except:\n",
    "        return None\n",
    "    else:\n",
    "        return titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autor(url):\n",
    "    try:\n",
    "        autor = url.find_element(By.XPATH, './/a[contains(@class, \"c_a_a\")]').text\n",
    "    except:\n",
    "        autor = None\n",
    "    return autor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ciudad(url):\n",
    "    try:\n",
    "        ciudad = url.find_element(By.XPATH, './/span[contains(@class, \"c_a_l\")]').text\n",
    "    except:\n",
    "        ciudad = None\n",
    "    return ciudad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fecha(url):\n",
    "    try:\n",
    "        fecha = url.find_element(By.XPATH, './/time').text.split()[:3]\n",
    "        fecha_pub = \" \".join(fecha)\n",
    "    except:\n",
    "        fecha_pub = None\n",
    "    return fecha_pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resumen(url):\n",
    "    try:\n",
    "        resumen = url.find_element(By.XPATH, './/p').text\n",
    "    except:\n",
    "        resumen = None\n",
    "    return resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tema(url):\n",
    "    try:\n",
    "        tema = url.find_element(By.XPATH, './/span[contains(@class, \"c_k\")]').text\n",
    "    except:\n",
    "        tema = None\n",
    "    return tema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imag(url):\n",
    "    try:\n",
    "        imagen = url.find_element(By.XPATH, './/img').get_attribute('src')\n",
    "    except:\n",
    "        imagen = None\n",
    "    return imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empresa con la cual vamos a extraer los articulos\n",
    "empresa = input(\"Digite la empresa a extraer: \").lower()\n",
    "revista = \"elPais\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear driver... MODIFICAR DEPENDIENDO DEL NAVEGADOR\n",
    "driver = sel.webdriver.Edge()\n",
    "driver.get(f'https://elpais.com/buscador/?q={empresa}')\n",
    "time.sleep(2)\n",
    "\n",
    "# Si en 5 segundo no ha encontrado el elemento que se le pasa se detiene\n",
    "# Luego acepta los cookies\n",
    "WebDriverWait(driver, 5)\\\n",
    "    .until(EC.element_to_be_clickable((By.CSS_SELECTOR,\n",
    "                                      \"button.didomi-components-button didomi-button didomi-dismiss-button didomi-components-button--color didomi-button-highlight highlight-button\".replace(\" \", \".\"))))\\\n",
    "                                          .click()\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacar primer titular CON BASE DE DATOS INICIAL\n",
    "# titulares = []\n",
    "# princip = driver.find_element(By.XPATH,'.//h2[contains(@class,\"c_t \")]')\n",
    "# urlPrinc = princip.find_elements(By.XPATH,'./a')[0].get_attribute('href')\n",
    "# infPrinc = driver.find_element(By.XPATH,'.//div[contains(@class,\"c_a\")]')\n",
    "# aux = driver.find_element(By.XPATH,'.//article[contains(@class,\"c c-d c--m   \")]')\n",
    "# if not(bs.existedb(urlPrinc, revista)):\n",
    "#     tituloPrinc = get_titulo(princip)\n",
    "#     autorPrinc = get_autor(infPrinc)\n",
    "#     ciudadPrinc = get_ciudad(infPrinc)\n",
    "#     fechaPrinc = get_fecha(infPrinc)\n",
    "#     resumenPrinc = get_resumen(aux)\n",
    "#     titulares.append({'Fecha Extraccion':datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "#                       'Titulo': tituloPrinc,\n",
    "#                       'Fecha Publicacion':fechaPrinc,\n",
    "#                       'URL': urlPrinc,\n",
    "#                       'Resumen': resumenPrinc,\n",
    "#                       'Autor': autorPrinc,\n",
    "#                       'Ciudad Publicacion': ciudadPrinc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"c c-d _g _g-md c-m-l c--m-n\" Contiene tema\n",
    "# TODO: Tener en cuenta que mientras mas se baja mas articulos aparacen\n",
    "articulos_Imag = driver.find_elements(By.XPATH, './/article[contains(@class, \"c c-d _g _g-md c-m-l c--m\")]')\n",
    "articulos_NoImag = driver.find_elements(By.XPATH, './/article[contains(@class, \"c c-d _g _g-md c-m-l c--m-n\")]')\n",
    "articulos = articulos_Imag + articulos_NoImag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulares = []\n",
    "for art in articulos:\n",
    "    aux = art.find_element(By.XPATH, './/h2[contains(@class, \"c_t\")]')\n",
    "    url = aux.find_element(By.XPATH,'.//a').get_attribute('href')\n",
    "    if not(bs.existedb(url, revista)):\n",
    "        inf = art.find_element(By.XPATH,'.//div[contains(@class,\"c_a\")]')\n",
    "        titulo = get_titulo(aux)\n",
    "        autor = get_autor(inf)\n",
    "        ciudad = get_ciudad(inf)\n",
    "        fecha = get_fecha(inf)\n",
    "        resumen = get_resumen(art)\n",
    "        tema = get_tema(art)\n",
    "        if art in articulos_Imag:\n",
    "            imagen = get_imag(art)\n",
    "        else:\n",
    "            imagen = None\n",
    "        titulares.append({'Fecha Extraccion':datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        'Titulo': titulo,\n",
    "                        'Fecha Publicacion':fecha,\n",
    "                        'Tema': tema,\n",
    "                        'Resumen': resumen,\n",
    "                        'URL': url,\n",
    "                        'Imagen': imagen,\n",
    "                        'Empresa': empresa,\n",
    "                        'Autor': autor\n",
    "                        # 'Contenido': contenido,\n",
    "                        # 'Ciudad Publicacion': ciudad,\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['Fecha Extraccion', 'Titulo', 'Fecha Publicacion', 'Tema',\n",
    "            'Resumen', 'URL', 'Imagen', 'Empresa', 'Autor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para AGREGAR titulares a un archivo.\n",
    "with open(f'../data/raw/{revista}.csv', 'a', newline='', errors='ignore') as csv_file:\n",
    "    dict_object = csv.DictWriter(csv_file, fieldnames=columnas) \n",
    "  \n",
    "    dict_object.writerows(titulares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para crear un NUEVO archivo con los titulares\n",
    "pd.json_normalize(titulares).to_csv(f'../data/raw/{revista}.csv',index=False, encoding='latin-1', errors='ignore', columns=columnas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
