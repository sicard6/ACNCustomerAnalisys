{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium as sel\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import base as bs\n",
    "import ElTiempoFunciones as etf\n",
    "\n",
    "import os as os\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerias que puedo mirar luego en detalle\n",
    "\n",
    "from selenium.webdriver.common.by import By\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('config.json')\n",
    "empresas = json.load(f)\n",
    "\n",
    "if not os.path.exists('../data/raw/eltiempo.csv'):\n",
    "    os.makedirs('../data/raw/eltiempo.csv')\n",
    "    \n",
    "#for i in empresas['LaRepublica']:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empresa con la cual vamos a extraer los articulos\n",
    "# TODO Tener una lista que itere por todos lo clientes\n",
    "empresa = input(\"Digite la empresa a extraer: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cerar driver... MODIFICAR DEPENDIENDO DEL NAVEGADOR\n",
    "driver = sel.webdriver.Edge()\n",
    "driver.get(f'https://www.eltiempo.com/buscar?q={empresa}')\n",
    "# time.sleep(2)\n",
    "driver.implicitly_wait(10) #Nueva metodología de wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar el class que abarca a toda la página \n",
    "# buscar = driver.find_element(By.XPATH,'//*[@id=\"main-container\"]/div[16]/div[2]')\n",
    "# articulos = buscar.find_elements(By.CLASS_NAME,\"listing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.eltiempo.com/buscar/2766?q=ecopetrol\n"
     ]
    }
   ],
   "source": [
    "# El número total de ventanas que tiene la búsqueda\n",
    "\n",
    "# total_num_ventanas = driver.find_element(By.XPATH,'//*[@id=\"main-container\"]/div[16]/div[2]/div[2]/div[2]/div/div[11]/div/ul/li[10]/a').get_attribute('href')\n",
    "# print(total_num_ventanas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_ventanas = f'https://www.eltiempo.com/buscar/20?q=ecopetrol' # Solo para el test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulares=[]\n",
    "get_url = driver.current_url\n",
    "pag_actual = 1\n",
    "\n",
    "\n",
    "while(get_url != total_num_ventanas):\n",
    "        buscar = driver.find_element(By.XPATH,'//*[@id=\"main-container\"]/div[16]/div[2]')\n",
    "        articulos = buscar.find_elements(By.CLASS_NAME,\"listing\")\n",
    "        for articulos in articulos:\n",
    "                aux = articulos.find_element(By.XPATH, './/h3[contains(@class, \"title-container\")]')\n",
    "                url = aux.find_element(By.XPATH,'.//a').get_attribute('href')\n",
    "                # print(url)\n",
    "\n",
    "                if not(bs.existedb(url, \"eltiempo\")):\n",
    "\n",
    "                        titulo = articulos.find_element(By.CLASS_NAME,\"title-container\").text\n",
    "                        # print(titulo)\n",
    "                        resumen = articulos.find_element(By.CLASS_NAME,\"epigraph-container\").text\n",
    "                        # print(resumen)\n",
    "                        fechaPub = articulos.find_element(By.CLASS_NAME,\"published-at\").text\n",
    "                        # print(fechaPub)\n",
    "                        tema = articulos.find_element(By.CLASS_NAME,\"category\").text\n",
    "                        # print(tema)\n",
    "                        \n",
    "\n",
    "                        titulares.append({'Fecha Extraccion':datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                                        'Titulo':titulo,\n",
    "                                        'Fecha Publicacion':fechaPub,\n",
    "                                        'Tema':tema,\n",
    "                                        'URL':url,\n",
    "                                        'Resumen':resumen,\n",
    "                                        'Empresa':empresa})\n",
    "        pag_actual=pag_actual+1\n",
    "        lik = driver.get(f'https://www.eltiempo.com/buscar/{pag_actual}?q=ecopetrol')\n",
    "        driver.implicitly_wait(10) #Nueva metodología de wait\n",
    "        get_url = driver.current_url\n",
    "# driver.quit()\n",
    "# print(titulares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "buscar = driver.find_element(By.XPATH,'//*[@id=\"main-container\"]/div[16]/div[2]')\n",
    "articulos = buscar.find_elements(By.CLASS_NAME,\"listing\")\n",
    "for articulos in articulos:\n",
    "        titulo = articulos.find_element(By.CLASS_NAME,\"title-container\").text\n",
    "        # print(titulo)\n",
    "        resumen = articulos.find_element(By.CLASS_NAME,\"epigraph-container\").text\n",
    "        # print(resumen)\n",
    "        fechaPub = articulos.find_element(By.CLASS_NAME,\"published-at\").text\n",
    "        # print(fechaPub)\n",
    "        tema = articulos.find_element(By.CLASS_NAME,\"category\").text\n",
    "        # print(tema)\n",
    "        aux = articulos.find_element(By.XPATH, './/h3[contains(@class, \"title-container\")]')\n",
    "        url = aux.find_element(By.XPATH,'.//a').get_attribute('href')\n",
    "        # print(url)\n",
    "\n",
    "        titulares.append({'Fecha Extraccion':datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        'Titulo':titulo,\n",
    "                        'Fecha Publicacion':fechaPub,\n",
    "                        'Tema':tema,\n",
    "                        'URL':url,\n",
    "                        'Resumen':resumen,\n",
    "                        'Empresa':empresa})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['Fecha Extraccion','Titulo', 'Fecha Publicacion','Resumen','URL','Empresa','Tema']\n",
    "# Para AGREGAR titulares a un archivo.\n",
    "with open('../data/raw/eltiempo.csv', 'a', newline='', errors='ignore') as csv_file:\n",
    "    dict_object = csv.DictWriter(csv_file, fieldnames=columnas) \n",
    "  \n",
    "    dict_object.writerows(titulares)\n",
    "\n",
    "#Para crear un NUEVO archivo con los titulares\n",
    "pd.json_normalize(titulares).to_csv(f'../data/raw/eltiempo.csv',index=False, encoding='latin-1', errors='ignore', columns=columnas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
