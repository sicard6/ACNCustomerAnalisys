{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium as sel\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import base as bs\n",
    "import ElTiempoFunciones as etf\n",
    "\n",
    "import os as os\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('config.json')\n",
    "empresas = json.load(f)\n",
    "\n",
    "if not os.path.exists('../data/raw/eltiempo.csv'):\n",
    "    os.makedirs('../data/raw/eltiempo.csv')\n",
    "    \n",
    "#for i in empresas['LaRepublica']:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empresa con la cual vamos a extraer los articulos\n",
    "# TODO Tener una lista que itere por todos lo clientes\n",
    "empresa = input(\"Digite la empresa a extraer: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cerar driver... MODIFICAR DEPENDIENDO DEL NAVEGADOR\n",
    "driver = sel.webdriver.Edge()\n",
    "driver.get(f'https://www.eltiempo.com/buscar?q={empresa}')\n",
    "# time.sleep(2)\n",
    "driver.implicitly_wait(10) #Nueva metodología de wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.eltiempo.com/buscar/2767?q=ecopetrol\n"
     ]
    }
   ],
   "source": [
    "# El número total de ventanas que tiene la búsqueda\n",
    "\n",
    "total_num_ventanas = driver.find_element(By.XPATH,'//*[@id=\"main-container\"]/div[16]/div[2]/div[2]/div[2]/div/div[11]/div/ul/li[10]/a').get_attribute('href')\n",
    "print(total_num_ventanas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recolecta datos hasta la ventana 20 del Tiempo\n",
    "total_num_ventanas = f'https://www.eltiempo.com/buscar/2?q=ecopetrol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"c7de229052deea54873344adbb9d622d\", element=\"3fe7e253-e723-467c-bb2a-003fc21b7ccd\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c7de229052deea54873344adbb9d622d\", element=\"62654b0b-11ec-4858-8d60-653dd6a4d251\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c7de229052deea54873344adbb9d622d\", element=\"75518527-94b2-48c1-a177-738e20f3a1d8\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c7de229052deea54873344adbb9d622d\", element=\"3edf812a-1cab-4c9c-8b37-09d940ecb58f\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c7de229052deea54873344adbb9d622d\", element=\"3e3bb118-de0c-4990-93b4-7e83bafe9db0\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c7de229052deea54873344adbb9d622d\", element=\"99392abd-fafd-49ab-a2ad-6a77a75e2b09\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c7de229052deea54873344adbb9d622d\", element=\"a9a5ebbd-cb55-44ef-9e19-ea0c8a4ec631\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c7de229052deea54873344adbb9d622d\", element=\"267a7355-3450-4867-a219-642a60561c92\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c7de229052deea54873344adbb9d622d\", element=\"7cc947de-1b11-451d-828f-d7f5d84e011d\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c7de229052deea54873344adbb9d622d\", element=\"b88a6bdf-eec1-4a05-976c-816a2d986ca4\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c7de229052deea54873344adbb9d622d\", element=\"30d58022-fec0-4017-9ad3-bbf1ec97e7c5\")>]\n"
     ]
    }
   ],
   "source": [
    "titulares=[]\n",
    "get_url = driver.current_url\n",
    "pag_actual = 1\n",
    "\n",
    "while(get_url != total_num_ventanas):\n",
    "        buscar = driver.find_element(By.XPATH,'//*[@id=\"main-container\"]/div[16]/div[2]')\n",
    "        articulos = buscar.find_elements(By.CLASS_NAME,\"listing\")\n",
    "        \n",
    "        print(articulos)\n",
    "\n",
    "        for articulos in articulos:\n",
    "                aux = articulos.find_element(By.XPATH, './/h3[contains(@class, \"title-container\")]')\n",
    "                url = aux.find_element(By.XPATH,'.//a').get_attribute('href')\n",
    "                # print(url)\n",
    "\n",
    "                if not(bs.existedb(url, \"eltiempo\")):\n",
    "\n",
    "                        titulo = articulos.find_element(By.CLASS_NAME,\"title-container\").text\n",
    "                        # print(titulo)\n",
    "                        resumen = articulos.find_element(By.CLASS_NAME,\"epigraph-container\").text\n",
    "                        # print(resumen)\n",
    "                        fechaPub = articulos.find_element(By.CLASS_NAME,\"published-at\").text\n",
    "                        # print(fechaPub)\n",
    "                        tema = articulos.find_element(By.CLASS_NAME,\"category\").text\n",
    "                        # print(tema)\n",
    "                        \n",
    "\n",
    "                        titulares.append({'Fecha Extraccion':datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                                        'Titulo':titulo,\n",
    "                                        'Fecha Publicacion':fechaPub,\n",
    "                                        'Tema':tema,\n",
    "                                        'URL':url,\n",
    "                                        'Resumen':resumen,\n",
    "                                        'Empresa':empresa})\n",
    "        pag_actual=pag_actual+1\n",
    "        lik = driver.get(f'https://www.eltiempo.com/buscar/{pag_actual}?q=ecopetrol')\n",
    "        driver.implicitly_wait(10) #Nueva metodología de wait\n",
    "        get_url = driver.current_url\n",
    "# driver.quit()\n",
    "# print(titulares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "buscar = driver.find_element(By.XPATH,'//*[@id=\"main-container\"]/div[16]/div[2]')\n",
    "articulos = buscar.find_elements(By.CLASS_NAME,\"listing\")\n",
    "\n",
    "for articulos in articulos:\n",
    "        if not(bs.existedb(url, \"eltiempo\")):\n",
    "                titulo = articulos.find_element(By.CLASS_NAME,\"title-container\").text\n",
    "                # print(titulo)\n",
    "                resumen = articulos.find_element(By.CLASS_NAME,\"epigraph-container\").text\n",
    "                # print(resumen)\n",
    "                fechaPub = articulos.find_element(By.CLASS_NAME,\"published-at\").text\n",
    "                # print(fechaPub)\n",
    "                tema = articulos.find_element(By.CLASS_NAME,\"category\").text\n",
    "                # print(tema)\n",
    "                aux = articulos.find_element(By.XPATH, './/h3[contains(@class, \"title-container\")]')\n",
    "                url = aux.find_element(By.XPATH,'.//a').get_attribute('href')\n",
    "                # print(url)\n",
    "\n",
    "                titulares.append({'Fecha Extraccion':datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                                'Titulo':titulo,\n",
    "                                'Fecha Publicacion':fechaPub,\n",
    "                                'Tema':tema,\n",
    "                                'URL':url,\n",
    "                                'Resumen':resumen,\n",
    "                                'Empresa':empresa})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['Fecha Extraccion','Titulo', 'Fecha Publicacion','Resumen','URL','Empresa','Tema']\n",
    "\n",
    "# Borra los duplicados\n",
    "result = [] \n",
    "[result.append(x) for x in titulares if x not in result] \n",
    "\n",
    "# Para AGREGAR titulares a un archivo.\n",
    "with open('../data/raw/eltiempo.csv', 'a', newline='', errors='ignore') as csv_file:\n",
    "    dict_object = csv.DictWriter(csv_file, fieldnames=columnas) \n",
    "  \n",
    "    dict_object.writerows(result)\n",
    "\n",
    "#Para crear un NUEVO archivo con los titulares\n",
    "# pd.json_normalize(titulares).to_csv(f'../data/raw/eltiempo.csv',index=False, encoding='latin-1', errors='ignore', columns=columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making data frame from csv file\n",
    "# data = pd.read_csv(r'../data/raw/eltiempo.csv')\n",
    "\n",
    "# # dropping ALL duplicate values\n",
    "# data.drop_duplicates(subset=\"First Name\",\n",
    "#                      keep=False, inplace=True)\n",
    "  \n",
    "# # displaying data\n",
    "# data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
