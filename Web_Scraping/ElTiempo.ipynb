{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium as sel\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import base as bs\n",
    "import ElTiempoFunciones as etf\n",
    "\n",
    "import os as os\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('config.json')\n",
    "empresas = json.load(f)\n",
    "\n",
    "if not os.path.exists('../data/raw/eltiempo.csv'):\n",
    "    os.makedirs('../data/raw/eltiempo.csv')\n",
    "    \n",
    "#for i in empresas['LaRepublica']:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empresa con la cual vamos a extraer los articulos\n",
    "# TODO Tener una lista que itere por todos lo clientes\n",
    "empresa = input(\"Digite la empresa a extraer: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cerar driver... MODIFICAR DEPENDIENDO DEL NAVEGADOR\n",
    "driver = sel.webdriver.Edge()\n",
    "driver.get(f'https://www.eltiempo.com/buscar?q={empresa}')\n",
    "# time.sleep(2)\n",
    "driver.implicitly_wait(10) #Nueva metodología de wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.eltiempo.com/buscar/2767?q=ecopetrol\n"
     ]
    }
   ],
   "source": [
    "# El número total de ventanas que tiene la búsqueda\n",
    "\n",
    "total_num_ventanas = driver.find_element(By.XPATH,'//*[@id=\"main-container\"]/div[16]/div[2]/div[2]/div[2]/div/div[11]/div/ul/li[10]/a').get_attribute('href')\n",
    "print(total_num_ventanas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recolecta datos hasta la ventana 20 del Tiempo\n",
    "total_num_ventanas = f'https://www.eltiempo.com/buscar/20?q=ecopetrol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulares=[]\n",
    "get_url = driver.current_url\n",
    "pag_actual = 1\n",
    "\n",
    "while(get_url != total_num_ventanas):\n",
    "        buscar = driver.find_element(By.XPATH,'//*[@id=\"main-container\"]/div[16]/div[2]')\n",
    "        articulos = buscar.find_elements(By.CLASS_NAME,\"listing\")\n",
    "\n",
    "        for articulos in articulos:\n",
    "                aux = articulos.find_element(By.XPATH, './/h3[contains(@class, \"title-container\")]')\n",
    "                url = aux.find_element(By.XPATH,'.//a').get_attribute('href')\n",
    "                # print(url)\n",
    "\n",
    "                if not(bs.existedb(url, \"eltiempo\")):\n",
    "\n",
    "                        titulo = articulos.find_element(By.CLASS_NAME,\"title-container\").text\n",
    "                        # print(titulo)\n",
    "                        resumen = articulos.find_element(By.CLASS_NAME,\"epigraph-container\").text\n",
    "                        # print(resumen)\n",
    "                        fechaPub = articulos.find_element(By.CLASS_NAME,\"published-at\").text\n",
    "                        # print(fechaPub)\n",
    "                        tema = articulos.find_element(By.CLASS_NAME,\"category\").text\n",
    "                        # print(tema)\n",
    "                        \n",
    "\n",
    "                        titulares.append({'Fecha Extraccion':datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                                        'Titulo':titulo,\n",
    "                                        'Fecha Publicacion':fechaPub,\n",
    "                                        'Tema':tema,\n",
    "                                        'URL':url,\n",
    "                                        'Resumen':resumen,\n",
    "                                        'Empresa':empresa})\n",
    "        pag_actual=pag_actual+1\n",
    "        driver.get(f'https://www.eltiempo.com/buscar/{pag_actual}?q=ecopetrol')\n",
    "        driver.implicitly_wait(10) # Wait mientras abre la ventana\n",
    "        get_url = driver.current_url\n",
    "# driver.quit()\n",
    "# print(titulares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "buscar = driver.find_element(By.XPATH,'//*[@id=\"main-container\"]/div[16]/div[2]')\n",
    "articulos = buscar.find_elements(By.CLASS_NAME,\"listing\")\n",
    "\n",
    "for articulos in articulos:\n",
    "        if not(bs.existedb(url, \"eltiempo\")):\n",
    "                titulo = articulos.find_element(By.CLASS_NAME,\"title-container\").text\n",
    "                # print(titulo)\n",
    "                resumen = articulos.find_element(By.CLASS_NAME,\"epigraph-container\").text\n",
    "                # print(resumen)\n",
    "                fechaPub = articulos.find_element(By.CLASS_NAME,\"published-at\").text\n",
    "                # print(fechaPub)\n",
    "                tema = articulos.find_element(By.CLASS_NAME,\"category\").text\n",
    "                # print(tema)\n",
    "                aux = articulos.find_element(By.XPATH, './/h3[contains(@class, \"title-container\")]')\n",
    "                url = aux.find_element(By.XPATH,'.//a').get_attribute('href')\n",
    "                # print(url)\n",
    "\n",
    "                titulares.append({'Fecha Extraccion':datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                                'Titulo':titulo,\n",
    "                                'Fecha Publicacion':fechaPub,\n",
    "                                'Tema':tema,\n",
    "                                'URL':url,\n",
    "                                'Resumen':resumen,\n",
    "                                'Empresa':empresa})\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para borrar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Borra los duplicados\n",
    "result = [] \n",
    "[result.append(x) for x in titulares if x not in result]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para agregar la info en un archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['Fecha Extraccion','Titulo', 'Fecha Publicacion','Resumen','URL','Empresa','Tema']\n",
    "\n",
    "# Para AGREGAR titulares a un archivo.\n",
    "with open('../data/raw/eltiempo.csv', 'a', newline='', errors='ignore') as csv_file:\n",
    "    dict_object = csv.DictWriter(csv_file, fieldnames=columnas) \n",
    "  \n",
    "    dict_object.writerows(result)\n",
    "\n",
    "#Para crear un NUEVO archivo con los titulares\n",
    "# pd.json_normalize(titulares).to_csv(f'../data/raw/eltiempo.csv',index=False, encoding='latin-1', errors='ignore', columns=columnas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
