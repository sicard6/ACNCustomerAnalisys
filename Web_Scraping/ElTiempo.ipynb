{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium as sel\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import base as bs\n",
    "import ElTiempoFunciones as etf\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "import os as os\n",
    "import csv\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('config.json')\n",
    "empresas = json.load(f)\n",
    "\n",
    "if not os.path.exists('../data/raw/eltiempo.csv'):\n",
    "    os.makedirs('../data/raw/eltiempo.csv')\n",
    "    \n",
    "#for i in empresas['LaRepublica']:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empresa con la cual vamos a extraer los articulos\n",
    "# TODO Tener una lista que itere por todos lo clientes\n",
    "empresa = input(\"Digite la empresa a extraer: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cerar driver... MODIFICAR DEPENDIENDO DEL NAVEGADOR\n",
    "driver = sel.webdriver.Edge()\n",
    "driver.get(f'https://www.eltiempo.com/buscar?q={empresa}')\n",
    "# time.sleep(2)\n",
    "driver.implicitly_wait(10) #Nueva metodología de wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.eltiempo.com/buscar/2768?q=ecopetrol\n"
     ]
    }
   ],
   "source": [
    "# El número total de ventanas que tiene la búsqueda\n",
    "\n",
    "total_num_ventanas = driver.find_element(By.XPATH,'//*[@id=\"main-container\"]/div[16]/div[2]/div[2]/div[2]/div/div[11]/div/ul/li[10]/a').get_attribute('href')\n",
    "print(total_num_ventanas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recolecta datos hasta la ventana 20 del periódico El Tiempo\n",
    "# total_num_ventanas = f'https://www.eltiempo.com/buscar/20?q={empresa}'\n",
    "\n",
    "# Para las pruebas: Recolecta datos hasta la ventana 2 del periódico El Tiempo\n",
    "total_num_ventanas = f'https://www.eltiempo.com/buscar/20?q={empresa}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulares=[]\n",
    "get_url = driver.current_url\n",
    "pag_actual = 1\n",
    "\n",
    "while(get_url != total_num_ventanas):\n",
    "        buscar = driver.find_element(By.XPATH,'//*[@id=\"main-container\"]/div[16]/div[2]/div[2]/div[2]/div')\n",
    "        articulos = buscar.find_elements(By.CLASS_NAME,\"listing\")\n",
    "\n",
    "        for articulos in articulos:\n",
    "                aux = articulos.find_element(By.XPATH, './/h3[contains(@class, \"title-container\")]')\n",
    "                url = aux.find_element(By.XPATH,'.//a').get_attribute('href')\n",
    "                # print(url)\n",
    "                if not(bs.existedb(url, \"eltiempo\")):\n",
    "                        titulo = articulos.find_element(By.CLASS_NAME,\"title-container\").text\n",
    "                        # print(titulo)\n",
    "                        resumen = articulos.find_element(By.CLASS_NAME,\"epigraph-container\").text\n",
    "                        # print(resumen)\n",
    "                        fechaPub = articulos.find_element(By.CLASS_NAME,\"published-at\").text\n",
    "                        # print(fechaPub)\n",
    "                        tema = articulos.find_element(By.CLASS_NAME,\"category\").text\n",
    "                        # print(tema)\n",
    "                        titulares.append({'Fecha Extraccion':datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                                        'Titulo':titulo,\n",
    "                                        'Fecha Publicacion':fechaPub,\n",
    "                                        'Tema':tema,\n",
    "                                        'URL':url,\n",
    "                                        'Resumen':resumen,\n",
    "                                        'Empresa':empresa})\n",
    "\n",
    "        pag_actual=pag_actual+1\n",
    "        driver.get(f'https://www.eltiempo.com/buscar/{pag_actual}?q={empresa}')\n",
    "        driver.implicitly_wait(10) # Wait mientras abre la ventana\n",
    "        get_url = driver.current_url\n",
    "# print(titulares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.eltiempo.com/economia/empresas/ecopetrol-se-seguiran-necesitando-las-regalias-e-impuestos-del-petroleo-735130\n"
     ]
    }
   ],
   "source": [
    "buscar = driver.find_element(By.XPATH,'//*[@id=\"main-container\"]/div[16]/div[2]/div[2]/div[2]/div')\n",
    "articulos = buscar.find_elements(By.CLASS_NAME,\"listing\")\n",
    "\n",
    "for articulos in articulos:\n",
    "        if not(bs.existedb(url, \"eltiempo\")):\n",
    "                titulo = articulos.find_element(By.CLASS_NAME,\"title-container\").text\n",
    "                # print(titulo)\n",
    "                resumen = articulos.find_element(By.CLASS_NAME,\"epigraph-container\").text\n",
    "                # print(resumen)\n",
    "                fechaPub = articulos.find_element(By.CLASS_NAME,\"published-at\").text\n",
    "                # print(fechaPub)\n",
    "                tema = articulos.find_element(By.CLASS_NAME,\"category\").text\n",
    "                # print(tema)\n",
    "                aux = articulos.find_element(By.XPATH, './/h3[contains(@class, \"title-container\")]')\n",
    "                url = aux.find_element(By.XPATH,'.//a').get_attribute('href')\n",
    "                # print(url)\n",
    "\n",
    "                titulares.append({'Fecha Extraccion':datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                                'Titulo':titulo,\n",
    "                                'Fecha Publicacion':fechaPub,\n",
    "                                'Tema':tema,\n",
    "                                'URL':url,\n",
    "                                'Resumen':resumen,\n",
    "                                'Empresa':empresa})\n",
    "\n",
    "print(url)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrae info de cada URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error en el articulo con link a:  https://www.eltiempo.com/economia/sectores/petroleo-puede-el-turismo-reemplazarlo-en-colombia-en-el-corto-plazo-735424\n",
      "error en el articulo con link a:  https://www.eltiempo.com/economia/sectores/reacciones-al-anuncio-de-ministra-de-minas-sobre-exploracion-petrolera-735468\n",
      "error en el articulo con link a:  https://www.eltiempo.com/economia/sectores/colombia-exploracion-petrolera-efectos-economicos-de-frenar-contratos-735278\n",
      "error en el articulo con link a:  https://www.eltiempo.com/podcast/el-primer-cafe/no-explorar-petroleo-gas-y-carbon-el-nuevo-reto-del-gobierno-nacional-735320\n"
     ]
    }
   ],
   "source": [
    "# Inicializa los cookies del navegador \n",
    "driver.delete_all_cookies()\n",
    "\n",
    "# Busca cada articulo y las almacena en la lista de titulares\n",
    "for tit in titulares:\n",
    "    # clear all cookies in scope of session\n",
    "    driver.get(tit['URL'])\n",
    "    driver.implicitly_wait(10) #Nueva metodología de wait\n",
    "\n",
    "\n",
    "    ignored_exceptions=(NoSuchElementException,StaleElementReferenceException)\n",
    "    contenido = ''\n",
    "    try :\n",
    "        html = WebDriverWait(driver,10,ignored_exceptions=ignored_exceptions).until(EC.presence_of_element_located((By.XPATH,'.//div[contains(@class,\"modulos public-side\")]')))\n",
    "        parrafos = html.find_elements(By.XPATH,'.//p') \n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            html = driver.find_element(By.XPATH,'.//div[contains(@class,\"modulos public-side\")]')\n",
    "            parrafos = html.find_elements(By.XPATH,'.//p')\n",
    "        except:\n",
    "            contenido = 'SIN PARRAFOS'\n",
    "        else:\n",
    "            for i in parrafos:\n",
    "                contenido += i.text\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            for i in parrafos:\n",
    "                contenido += i.text\n",
    "        except:\n",
    "            print('Error en el último for == el más dentro de \"for tit in titulares:\" externo')\n",
    "    \n",
    "    # agregar contenido al dict de titulares\n",
    "    tit['Contenido'] = contenido\n",
    "    driver.delete_all_cookies()\n",
    "    \n",
    "    #agregar lista de URLs de noticias relacionadas\n",
    "    # tit['RelNewsUrls'] = bs.obtener_articulos_relacionados_eltiempo(driver)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para agregar la info en un archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['Fecha Extraccion','Titulo', 'Fecha Publicacion','Resumen','URL','Empresa','Tema','Contenido']\n",
    "\n",
    "# Para AGREGAR titulares a un archivo.\n",
    "with open('../data/raw/eltiempo.csv', 'a', newline='', errors='ignore') as csv_file:\n",
    "    dict_object = csv.DictWriter(csv_file, fieldnames=columnas) \n",
    "  \n",
    "    dict_object.writerows(titulares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir los últimos datos de\n",
    "titulares[-1]\n",
    "\n",
    "# Cerrar navegador\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
