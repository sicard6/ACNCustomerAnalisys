{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/curated/contenido_procesado.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_contenido \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m../data/curated/contenido_procesado.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8-sig\u001b[39;49m\u001b[39m'\u001b[39;49m, index_col\u001b[39m=\u001b[39;49m[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/curated/contenido_procesado.csv'"
     ]
    }
   ],
   "source": [
    "df_contenido = pd.read_csv('../data/curated/contenido_procesado.csv', encoding='utf-8-sig', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curated = pd.read_csv('../data/curated/curated_database.csv', encoding='utf-8-sig', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_curated, df_contenido, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Contenido_y', axis=1)\n",
    "df.rename(columns = {'Contenido_x': 'Contenido'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/curated/ensayo.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entidades = set()\n",
    "for lista in df['Entidades de Contenido'].values:\n",
    "    if type(lista) is str:\n",
    "        aux = lista.split(', ')\n",
    "        for palabra in aux:\n",
    "            entidades.add(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras = []\n",
    "for i, lista in enumerate(df['Contenido procesado'].values):\n",
    "    if type(lista) is str:\n",
    "        aux = lista.split(', ')\n",
    "        for palabra in aux:\n",
    "            if palabra in entidades:\n",
    "                palabras.append([i, palabra, 1])\n",
    "            else:\n",
    "                palabras.append([i, palabra, 0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apariciones(entidades, num=False):\n",
    "    '''Crear un diccionario de diccionarios para rastrear las coapariciones\n",
    "    de entidades.\n",
    "    Parameters\n",
    "    ----------\n",
    "    entidades: lista de las entidades\n",
    "    num       : si el diccionario de diccionarios debe o no inicializarse en 0 \n",
    "    (True) o en una lista vacía (False)\n",
    "    Returns\n",
    "    -------\n",
    "    Diccionario de diccionarios donde cada clave es cada entidad y cada valor\n",
    "    es un diccionario con todos las demás entidades como claves, y valores como \n",
    "    0 o [].\n",
    "    '''\n",
    "    \n",
    "    apariciones = {}\n",
    "    for entidad in entidades:\n",
    "        relaciones = {}\n",
    "        for relacion in entidades:\n",
    "            if relacion != entidad:\n",
    "\n",
    "                if num:\n",
    "                    relaciones[relacion] = 0\n",
    "\n",
    "                else:\n",
    "                    relaciones[relacion] = []\n",
    "        apariciones[entidad] = relacion\n",
    "    return apariciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, lists in enumerate(df['Contenido'].values):\n",
    "    if type(lists) is float:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha Extraccion</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Fecha Publicacion</th>\n",
       "      <th>Tema</th>\n",
       "      <th>URL</th>\n",
       "      <th>Imagen</th>\n",
       "      <th>Empresa</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>Resumen</th>\n",
       "      <th>Autor</th>\n",
       "      <th>Contenido</th>\n",
       "      <th>RelNewsUrls</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Contenido procesado</th>\n",
       "      <th>Contenido segmentado</th>\n",
       "      <th>Entidades de Contenido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>03-02-2023</td>\n",
       "      <td>Lo que tiene que ver Petro, y lo que no, con e...</td>\n",
       "      <td>15-07-2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.lasillavacia.com/historias/silla-n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ecopetrol</td>\n",
       "      <td>La Silla Vacía</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La Silla Vacía</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>03-02-2023</td>\n",
       "      <td>Ecopetrol también quiere opinar</td>\n",
       "      <td>30-05-2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.lasillavacia.com/historias/silla-n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ecopetrol</td>\n",
       "      <td>La Silla Vacía</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fecha Extraccion                                             Titulo  \\\n",
       "77        03-02-2023  Lo que tiene que ver Petro, y lo que no, con e...   \n",
       "100       03-02-2023                    Ecopetrol también quiere opinar   \n",
       "\n",
       "    Fecha Publicacion Tema                                                URL  \\\n",
       "77         15-07-2022  NaN  https://www.lasillavacia.com/historias/silla-n...   \n",
       "100        30-05-2021  NaN  https://www.lasillavacia.com/historias/silla-n...   \n",
       "\n",
       "    Imagen    Empresa          Fuente Resumen           Autor    Contenido  \\\n",
       "77     NaN  ecopetrol  La Silla Vacía     NaN  La Silla Vacía                \n",
       "100    NaN  ecopetrol  La Silla Vacía     NaN             NaN                \n",
       "\n",
       "    RelNewsUrls Tags Contenido procesado Contenido segmentado  \\\n",
       "77          NaN  NaN                 NaN                        \n",
       "100         NaN  NaN                 NaN                        \n",
       "\n",
       "    Entidades de Contenido  \n",
       "77                     NaN  \n",
       "100                    NaN  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Contenido.str.len() < 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Contenido procesado'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lista_palabras():\n",
    "    entidades = set()\n",
    "    for lista in df[f'Entidades de {columna}'].values:\n",
    "        if type(lista) is str:\n",
    "            aux = lista.split(', ')\n",
    "            for palabra in aux:\n",
    "                entidades.add(palabra)\n",
    "\n",
    "    palabras = []\n",
    "    for i in df.index:\n",
    "        lista = df.loc[i, 'Contenido procesado']\n",
    "        if type(lista) is str:\n",
    "            aux = lista.split(', ')\n",
    "            for palabra in aux:\n",
    "                if palabra in entidades:\n",
    "                    palabras.append([i, palabra, 1])\n",
    "                else:\n",
    "                    palabras.append([i, palabra, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lista_palabras(val_ent, val_pal, indice):\n",
    "    entidades = set(val_ent.split(', '))\n",
    "\n",
    "    palabras = val_pal.split(', ')\n",
    "    freq_pal = dict(nltk.FreqDist(palabras))\n",
    "    \n",
    "    lista = []\n",
    "    for key, value in freq_pal.items():\n",
    "        if key in entidades:\n",
    "            lista.append([key, value, indice, 1])\n",
    "        else:\n",
    "            lista.append([key, value, indice, 0])\n",
    "            \n",
    "    return pd.DataFrame(lista, columns=['Palabra', 'Frecuencia', 'ID_Articulo', 'Entidad'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palabra</th>\n",
       "      <th>Frecuencia</th>\n",
       "      <th>ID_Articulo</th>\n",
       "      <th>Entidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movimiento</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dólar</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>semanas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atrás</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>venía</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>aire</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Alexander</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Ríos</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>fundador</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Inverxia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Palabra  Frecuencia  ID_Articulo  Entidad\n",
       "0    movimiento           2            0        0\n",
       "1         dólar           8            0        0\n",
       "2       semanas           1            0        0\n",
       "3         atrás           1            0        0\n",
       "4         venía           1            0        0\n",
       "..          ...         ...          ...      ...\n",
       "230        aire           1            0        0\n",
       "231   Alexander           1            0        0\n",
       "232        Ríos           1            0        0\n",
       "233    fundador           1            0        0\n",
       "234    Inverxia           1            0        1\n",
       "\n",
       "[235 rows x 4 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_palabras(df.loc[0, 'Entidades de Contenido'], df.loc[0, 'Contenido procesado'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Fecha Extraccion</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Fecha Publicacion</th>\n",
       "      <th>Tema</th>\n",
       "      <th>URL</th>\n",
       "      <th>Imagen</th>\n",
       "      <th>Empresa</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>Resumen</th>\n",
       "      <th>Autor</th>\n",
       "      <th>Contenido</th>\n",
       "      <th>RelNewsUrls</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>2023-02-03 14:51:13</td>\n",
       "      <td>Felipe Bayón, difícil de reemplazar en la pres...</td>\n",
       "      <td>2023-01-23 00:00:00</td>\n",
       "      <td>Confidenciales</td>\n",
       "      <td>https://www.semana.com/confidenciales/articulo...</td>\n",
       "      <td>https://www.semana.com/resizer/vfF62WvmBdVguGl...</td>\n",
       "      <td>ecopetrol</td>\n",
       "      <td>Semana</td>\n",
       "      <td>Muchos líderes de opinión en el país coinciden...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SIN PARRAFOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Confidenciales Semana', 'Felipe Bayón Pardo'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>2023-02-03 14:54:41</td>\n",
       "      <td>Lo que tiene que ver Petro, y lo que no, con e...</td>\n",
       "      <td>2022-07-15 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.lasillavacia.com/historias/silla-n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ecopetrol</td>\n",
       "      <td>La Silla Vacía</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La Silla Vacía</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2023-02-03 14:54:43</td>\n",
       "      <td>Ecopetrol también quiere opinar</td>\n",
       "      <td>2021-05-30 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.lasillavacia.com/historias/silla-n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ecopetrol</td>\n",
       "      <td>La Silla Vacía</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>166</td>\n",
       "      <td>2023-02-03 15:26:54</td>\n",
       "      <td>Entre iguanas</td>\n",
       "      <td>2023-01-28 00:00:00</td>\n",
       "      <td>CARICATURAS</td>\n",
       "      <td>https://www.eltiempo.com/opinion/caricaturas/r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ecopetrol</td>\n",
       "      <td>El Tiempo</td>\n",
       "      <td>Caricatura de Guerreros</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SIN PARRAFOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249</td>\n",
       "      <td>2023-02-09 13:59:34</td>\n",
       "      <td>La radio local fue premiada en España</td>\n",
       "      <td>2018-11-15 00:00:00</td>\n",
       "      <td>CAJA FUERTE</td>\n",
       "      <td>https://www.larepublica.co/caja-fuerte/la-radi...</td>\n",
       "      <td>data:image/svg+xml,%3Csvg xmlns='http://www.w3...</td>\n",
       "      <td>caracol</td>\n",
       "      <td>La República</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SIN AUTOR</td>\n",
       "      <td>SIN PARRAFOS</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>302</td>\n",
       "      <td>2023-02-03 14:50:43</td>\n",
       "      <td>Este título es una prueba</td>\n",
       "      <td>2023-03-03</td>\n",
       "      <td>BOLSAS</td>\n",
       "      <td>https://www.google.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ensayo</td>\n",
       "      <td>ensayo</td>\n",
       "      <td>Este es el resumen del ensayo</td>\n",
       "      <td>ANDRÉS OSPINA PATIÑO</td>\n",
       "      <td>Acá debo escribir un contenido que se al menos...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     Fecha Extraccion  \\\n",
       "0     63  2023-02-03 14:51:13   \n",
       "1     78  2023-02-03 14:54:41   \n",
       "2    101  2023-02-03 14:54:43   \n",
       "3    166  2023-02-03 15:26:54   \n",
       "4    249  2023-02-09 13:59:34   \n",
       "5    302  2023-02-03 14:50:43   \n",
       "\n",
       "                                              Titulo    Fecha Publicacion  \\\n",
       "0  Felipe Bayón, difícil de reemplazar en la pres...  2023-01-23 00:00:00   \n",
       "1  Lo que tiene que ver Petro, y lo que no, con e...  2022-07-15 00:00:00   \n",
       "2                    Ecopetrol también quiere opinar  2021-05-30 00:00:00   \n",
       "3                                      Entre iguanas  2023-01-28 00:00:00   \n",
       "4              La radio local fue premiada en España  2018-11-15 00:00:00   \n",
       "5                          Este título es una prueba           2023-03-03   \n",
       "\n",
       "             Tema                                                URL  \\\n",
       "0  Confidenciales  https://www.semana.com/confidenciales/articulo...   \n",
       "1             NaN  https://www.lasillavacia.com/historias/silla-n...   \n",
       "2             NaN  https://www.lasillavacia.com/historias/silla-n...   \n",
       "3     CARICATURAS  https://www.eltiempo.com/opinion/caricaturas/r...   \n",
       "4     CAJA FUERTE  https://www.larepublica.co/caja-fuerte/la-radi...   \n",
       "5          BOLSAS                            https://www.google.com/   \n",
       "\n",
       "                                              Imagen    Empresa  \\\n",
       "0  https://www.semana.com/resizer/vfF62WvmBdVguGl...  ecopetrol   \n",
       "1                                                NaN  ecopetrol   \n",
       "2                                                NaN  ecopetrol   \n",
       "3                                                NaN  ecopetrol   \n",
       "4  data:image/svg+xml,%3Csvg xmlns='http://www.w3...    caracol   \n",
       "5                                                NaN     ensayo   \n",
       "\n",
       "           Fuente                                            Resumen  \\\n",
       "0          Semana  Muchos líderes de opinión en el país coinciden...   \n",
       "1  La Silla Vacía                                                NaN   \n",
       "2  La Silla Vacía                                                NaN   \n",
       "3       El Tiempo                            Caricatura de Guerreros   \n",
       "4    La República                                                NaN   \n",
       "5          ensayo                      Este es el resumen del ensayo   \n",
       "\n",
       "                  Autor                                          Contenido  \\\n",
       "0                   NaN                                       SIN PARRAFOS   \n",
       "1        La Silla Vacía                                                      \n",
       "2                   NaN                                                      \n",
       "3                   NaN                                       SIN PARRAFOS   \n",
       "4             SIN AUTOR                                       SIN PARRAFOS   \n",
       "5  ANDRÉS OSPINA PATIÑO  Acá debo escribir un contenido que se al menos...   \n",
       "\n",
       "  RelNewsUrls                                               Tags  \n",
       "0         NaN  ['Confidenciales Semana', 'Felipe Bayón Pardo'...  \n",
       "1         NaN                                                NaN  \n",
       "2         NaN                                                NaN  \n",
       "3         NaN                                                NaN  \n",
       "4          []                                                NaN  \n",
       "5         NaN                                                NaN  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv('../data/raw/database.csv',\n",
    "                     encoding='utf-8-sig', index_col=[0])\n",
    "df_curated = pd.read_csv(\n",
    "    '../data/curated/curated_database.csv', encoding='utf-8-sig', index_col=[0])\n",
    "len_curated = len(df_curated)\n",
    "# Verificar cuales articulos no han sido procesados\n",
    "df = df_raw[~df_raw['Titulo'].isin(df_curated['Titulo'])].reset_index()\n",
    "len_df = len(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ent = df_curated.loc[0, 'Entidades de Contenido']\n",
    "val_pal = df_curated.loc[0, 'Contenido procesado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_palabras = pd.read_csv('../data/curated/palabras.csv', encoding='utf-8-sig', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lista_ngramas(val_ent: str, val_pal: str, indice: int, n: int):\n",
    "    \"\"\"Función que genera la lista de todas las palabras del conjunto\n",
    "    de datos y obtiene la frecuencia de cada una por artículo, \n",
    "    especifica a que artículo pertenece y si es una entidad (1) o no\n",
    "    (0).\n",
    "\n",
    "    Args:\n",
    "        val_ent (str): cadena de entidades obtenida en el procesamiento\n",
    "        val_pal (str): cadena de palabras obtenida en el procesamiento\n",
    "        indice (int): indice del artículo al que corresponden las cadenas\n",
    "        n (int): tamaño de la subsecuencia del n-grama\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con el indice, la palabra, frecuencia de\n",
    "        aparición, ID del artículo al que pertenece. Si es solo una palabra\n",
    "        se incluye la columna de entidad que indica si lo es o no\n",
    "    \"\"\"\n",
    "    if type(val_ent) == float:\n",
    "        entidades = {}\n",
    "    else:\n",
    "        entidades = set(val_ent.split(', '))\n",
    "\n",
    "    palabras = val_pal.split(', ')\n",
    "    ngrams = list(nltk.ngrams(palabras, n))\n",
    "    freq_pal = dict(nltk.FreqDist(ngrams))\n",
    "\n",
    "    if n == 1:\n",
    "        lista = []\n",
    "        for key, value in freq_pal.items():\n",
    "            word = \", \".join(list(key))\n",
    "            if word in entidades:\n",
    "                lista.append([word, value, indice, 1])\n",
    "            else:\n",
    "                lista.append([word, value, indice, 0])\n",
    "        df_frec = pd.DataFrame(\n",
    "            lista, columns=['Palabra', 'Frecuencia', 'ID_Articulo', 'Entidad'])\n",
    "    return df_frec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_palabras = pd.DataFrame()\n",
    "for i in df_curated.index:\n",
    "    aux_palabras = lista_ngramas(df_curated.loc[i, 'Entidades de Contenido'],\n",
    "                                 df_curated.loc[i, 'Contenido procesado'], i, 1)\n",
    "    df_palabras = pd.concat([df_palabras, aux_palabras], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_palabras.to_csv('../data/curated/palabras.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('movimiento', 'dólar'): 1,\n",
       " ('dólar', 'semanas'): 1,\n",
       " ('semanas', 'atrás'): 1,\n",
       " ('atrás', 'venía'): 1,\n",
       " ('venía', 'mostrando'): 1,\n",
       " ('mostrando', 'comportamientos'): 1,\n",
       " ('comportamientos', 'bajistas'): 1,\n",
       " ('bajistas', 'constantes'): 1,\n",
       " ('constantes', 'viernes'): 1,\n",
       " ('viernes', 'enero'): 2,\n",
       " ('enero', 'sorprendió'): 1,\n",
       " ('sorprendió', 'leve'): 1,\n",
       " ('leve', 'repunte'): 1,\n",
       " ('repunte', 'presentó'): 1,\n",
       " ('presentó', 'miércoles'): 1,\n",
       " ('miércoles', 'febrero'): 1,\n",
       " ('febrero', 'fecha'): 1,\n",
       " ('fecha', 'comenzó'): 1,\n",
       " ('comenzó', 'caer'): 1,\n",
       " ('caer', 'nuevamente'): 1,\n",
       " ('nuevamente', 'comportamiento'): 1,\n",
       " ('comportamiento', 'duró'): 1,\n",
       " ('duró', 'volatilidad'): 1,\n",
       " ('volatilidad', 'moneda'): 1,\n",
       " ('moneda', 'viene'): 1,\n",
       " ('viene', 'acompañada'): 1,\n",
       " ('acompañada', 'serie'): 1,\n",
       " ('serie', 'sucesos'): 1,\n",
       " ('sucesos', 'nacionales'): 1,\n",
       " ('nacionales', 'internacionales'): 1,\n",
       " ('internacionales', 'semana'): 1,\n",
       " ('semana', 'excepción'): 1,\n",
       " ('excepción', 'evento'): 1,\n",
       " ('evento', 'clave'): 1,\n",
       " ('clave', 'semana'): 1,\n",
       " ('semana', 'decisión'): 1,\n",
       " ('decisión', 'reserva'): 1,\n",
       " ('reserva', 'federal'): 2,\n",
       " ('federal', 'tasas'): 1,\n",
       " ('tasas', 'interés'): 1,\n",
       " ('interés', 'mercado'): 1,\n",
       " ('mercado', 'cree'): 1,\n",
       " ('cree', 'anuncios'): 1,\n",
       " ('anuncios', 'cerca'): 1,\n",
       " ('cerca', 'finalización'): 1,\n",
       " ('finalización', 'ciclo'): 1,\n",
       " ('ciclo', 'subidas'): 1,\n",
       " ('subidas', 'tasas'): 1,\n",
       " ('tasas', 'unidos'): 1,\n",
       " ('unidos', 'asegura'): 1,\n",
       " ('asegura', 'david'): 1,\n",
       " ('david', 'cubides'): 1,\n",
       " ('cubides', 'director'): 1,\n",
       " ('director', 'investigaciones'): 1,\n",
       " ('investigaciones', 'económicas'): 1,\n",
       " ('económicas', 'alianza'): 1,\n",
       " ('alianza', 'entender'): 1,\n",
       " ('entender', 'comportamiento'): 1,\n",
       " ('comportamiento', 'dólar'): 2,\n",
       " ('dólar', 'semana'): 1,\n",
       " ('semana', 'analizar'): 1,\n",
       " ('analizar', 'viernes'): 1,\n",
       " ('enero', 'dólar'): 1,\n",
       " ('dólar', 'comenzó'): 1,\n",
       " ('comenzó', 'repuntar'): 1,\n",
       " ('repuntar', 'semana'): 1,\n",
       " ('semana', 'baja'): 1,\n",
       " ('baja', 'navegando'): 1,\n",
       " ('navegando', 'pesos'): 1,\n",
       " ('pesos', 'comportamiento'): 1,\n",
       " ('comportamiento', 'justo'): 1,\n",
       " ('justo', 'anunciara'): 1,\n",
       " ('anunciara', 'noche'): 1,\n",
       " ('noche', 'jueves'): 1,\n",
       " ('jueves', 'salida'): 1,\n",
       " ('salida', 'felipe'): 1,\n",
       " ('felipe', 'bayón'): 1,\n",
       " ('bayón', 'presidencia'): 1,\n",
       " ('presidencia', 'ecopetrol'): 1,\n",
       " ('ecopetrol', 'marzo'): 1,\n",
       " ('marzo', 'expertos'): 1,\n",
       " ('expertos', 'aseguraron'): 2,\n",
       " ('aseguraron', 'única'): 1,\n",
       " ('única', 'razón'): 1,\n",
       " ('razón', 'alza'): 1,\n",
       " ('alza', 'moneda'): 1,\n",
       " ('moneda', 'dividiéramos'): 1,\n",
       " ('dividiéramos', 'subida'): 1,\n",
       " ('subida', 'dólar'): 1,\n",
       " ('dólar', 'frente'): 1,\n",
       " ('frente', 'cierre'): 1,\n",
       " ('cierre', 'jueves'): 1,\n",
       " ('jueves', 'diría'): 1,\n",
       " ('diría', 'reacción'): 1,\n",
       " ('reacción', 'mercado'): 1,\n",
       " ('mercado', 'salida'): 1,\n",
       " ('salida', 'bayón'): 1,\n",
       " ('bayón', 'ecopetrol'): 1,\n",
       " ('ecopetrol', 'importante'): 1,\n",
       " ('importante', 'catástrofe'): 1,\n",
       " ('catástrofe', 'aplica'): 1,\n",
       " ('aplica', 'especie'): 1,\n",
       " ('especie', 'escepticismo'): 1,\n",
       " ('escepticismo', 'inversionistas'): 1,\n",
       " ('inversionistas', 'asegura'): 1,\n",
       " ('asegura', 'wilson'): 1,\n",
       " ('wilson', 'tovar'): 1,\n",
       " ('tovar', 'gerente'): 1,\n",
       " ('gerente', 'investigaciones'): 1,\n",
       " ('investigaciones', 'firma'): 1,\n",
       " ('firma', 'acciones'): 1,\n",
       " ('acciones', 'sebastián'): 1,\n",
       " ('sebastián', 'toro'): 1,\n",
       " ('toro', 'trader'): 1,\n",
       " ('trader', 'especialista'): 1,\n",
       " ('especialista', 'economía'): 1,\n",
       " ('economía', 'asesor'): 1,\n",
       " ('asesor', 'renta'): 1,\n",
       " ('renta', 'bolsa'): 1,\n",
       " ('bolsa', 'presionando'): 1,\n",
       " ('presionando', 'dólar'): 1,\n",
       " ('dólar', 'alza'): 1,\n",
       " ('alza', 'comunicado'): 1,\n",
       " ('comunicado', 'presidente'): 1,\n",
       " ('presidente', 'regulación'): 1,\n",
       " ('regulación', 'servicios'): 1,\n",
       " ('servicios', 'públicos'): 1,\n",
       " ('públicos', 'comienza'): 1,\n",
       " ('comienza', 'oler'): 1,\n",
       " ('oler', 'control'): 1,\n",
       " ('control', 'precios'): 1,\n",
       " ('precios', 'funcionado'): 1,\n",
       " ('funcionado', 'partes'): 1,\n",
       " ('partes', 'subida'): 1,\n",
       " ('subida', 'moneda'): 1,\n",
       " ('moneda', 'enero'): 1,\n",
       " ('enero', 'lunes'): 1,\n",
       " ('lunes', 'martes'): 1,\n",
       " ('martes', 'comenzando'): 1,\n",
       " ('comenzando', 'semana'): 1,\n",
       " ('semana', 'cifra'): 1,\n",
       " ('cifra', 'veía'): 1,\n",
       " ('veía', 'enero'): 1,\n",
       " ('enero', 'expertos'): 1,\n",
       " ('aseguraron', 'causa'): 1,\n",
       " ('causa', 'reacciones'): 1,\n",
       " ('reacciones', 'frente'): 1,\n",
       " ('frente', 'anuncio'): 1,\n",
       " ('anuncio', 'ecopetrol'): 1,\n",
       " ('ecopetrol', 'reporte'): 1,\n",
       " ('reporte', 'ministra'): 1,\n",
       " ('ministra', 'minas'): 1,\n",
       " ('minas', 'antesala'): 1,\n",
       " ('antesala', 'subida'): 1,\n",
       " ('subida', 'tasas'): 1,\n",
       " ('tasas', 'llevó'): 1,\n",
       " ('llevó', 'cabo'): 1,\n",
       " ('cabo', 'miércoles'): 1,\n",
       " ('miércoles', 'miércoles'): 1,\n",
       " ('miércoles', 'reunión'): 1,\n",
       " ('reunión', 'colombia'): 1,\n",
       " ('colombia', 'volvió'): 1,\n",
       " ('volvió', 'testigo'): 1,\n",
       " ('testigo', 'leve'): 1,\n",
       " ('leve', 'reducción'): 1,\n",
       " ('reducción', 'divisa'): 1,\n",
       " ('divisa', 'cerró'): 1,\n",
       " ('cerró', 'toro'): 1,\n",
       " ('toro', 'caímos'): 1,\n",
       " ('caímos', 'piso'): 1,\n",
       " ('piso', 'rebotamos'): 1,\n",
       " ('rebotamos', 'piso'): 1,\n",
       " ('piso', 'gente'): 1,\n",
       " ('gente', 'anuncios'): 1,\n",
       " ('anuncios', 'reserva'): 1,\n",
       " ('federal', 'esperados'): 1,\n",
       " ('esperados', 'incrementando'): 1,\n",
       " ('incrementando', 'tasas'): 1,\n",
       " ('tasas', 'puntos'): 1,\n",
       " ('puntos', 'básicos'): 1,\n",
       " ('básicos', 'evidenciando'): 1,\n",
       " ('evidenciando', 'baja'): 1,\n",
       " ('baja', 'aumento'): 1,\n",
       " ('aumento', 'reunión'): 1,\n",
       " ('reunión', 'consecutiva'): 1,\n",
       " ('consecutiva', 'banco'): 1,\n",
       " ('banco', 'central'): 1,\n",
       " ('central', 'mantuvo'): 1,\n",
       " ('mantuvo', 'materia'): 1,\n",
       " ('materia', 'costos'): 1,\n",
       " ('costos', 'endeudamiento'): 1,\n",
       " ('endeudamiento', 'nivel'): 1,\n",
       " ('nivel', 'alto'): 1,\n",
       " ('alto', 'jueves'): 1,\n",
       " ('jueves', 'dólar'): 1,\n",
       " ('dólar', 'volvió'): 1,\n",
       " ('volvió', 'sorprender'): 1,\n",
       " ('sorprender', 'cerrando'): 1,\n",
       " ('cerrando', 'promedio'): 1,\n",
       " ('promedio', 'comportamiento'): 1,\n",
       " ('comportamiento', 'vera'): 1,\n",
       " ('vera', 'nieto'): 1,\n",
       " ('nieto', 'economista'): 1,\n",
       " ('economista', 'jefe'): 1,\n",
       " ('jefe', 'capital'): 1,\n",
       " ('capital', 'explica'): 1,\n",
       " ('explica', 'movimiento'): 1,\n",
       " ('movimiento', 'tasas'): 1,\n",
       " ('tasas', 'bancos'): 1,\n",
       " ('bancos', 'centrales'): 1,\n",
       " ('centrales', 'subieron'): 1,\n",
       " ('subieron', 'magnitud'): 1,\n",
       " ('magnitud', 'dando'): 1,\n",
       " ('dando', 'menor'): 1,\n",
       " ('menor', 'percepción'): 1,\n",
       " ('percepción', 'riesgo'): 1,\n",
       " ('riesgo', 'favorecen'): 1,\n",
       " ('favorecen', 'compras'): 1,\n",
       " ('compras', 'países'): 1,\n",
       " ('países', 'emergentes'): 1,\n",
       " ('emergentes', 'colombia'): 1,\n",
       " ('colombia', 'paga'): 1,\n",
       " ('paga', 'tasas'): 1,\n",
       " ('tasas', 'altas'): 1,\n",
       " ('altas', 'dicha'): 1,\n",
       " ('dicha', 'duró'): 1,\n",
       " ('duró', 'moneda'): 1,\n",
       " ('moneda', 'abrió'): 1,\n",
       " ('abrió', 'viernes'): 1,\n",
       " ('viernes', 'repunte'): 1,\n",
       " ('repunte', 'pesos'): 1,\n",
       " ('pesos', 'frente'): 1,\n",
       " ('frente', 'vigente'): 1,\n",
       " ('vigente', 'comportamiento'): 1,\n",
       " ('comportamiento', 'jueves'): 1,\n",
       " ('jueves', 'vimos'): 1,\n",
       " ('vimos', 'demanda'): 1,\n",
       " ('demanda', 'dólares'): 1,\n",
       " ('dólares', 'acciones'): 1,\n",
       " ('acciones', 'unidos'): 1,\n",
       " ('unidos', 'valorizado'): 1,\n",
       " ('valorizado', 'significativamente'): 1,\n",
       " ('significativamente', 'apetito'): 1,\n",
       " ('apetito', 'inversiones'): 1,\n",
       " ('inversiones', 'mercados'): 1,\n",
       " ('mercados', 'acciones'): 1,\n",
       " ('acciones', 'globales'): 1,\n",
       " ('globales', 'indica'): 1,\n",
       " ('indica', 'acciones'): 1,\n",
       " ('acciones', 'tecnológicas'): 1,\n",
       " ('tecnológicas', 'jugando'): 1,\n",
       " ('jugando', 'papel'): 1,\n",
       " ('papel', 'importante'): 1,\n",
       " ('importante', 'comportamiento'): 1,\n",
       " ('dólar', 'cierre'): 1,\n",
       " ('cierre', 'conveniente'): 1,\n",
       " ('conveniente', 'sacar'): 1,\n",
       " ('sacar', 'préstamo'): 1,\n",
       " ('préstamo', 'invertir'): 1,\n",
       " ('invertir', 'comportamientos'): 1,\n",
       " ('comportamientos', 'dólar'): 1,\n",
       " ('dólar', 'personas'): 1,\n",
       " ('personas', 'verse'): 1,\n",
       " ('verse', 'influenciadas'): 1,\n",
       " ('influenciadas', 'invertir'): 1,\n",
       " ('invertir', 'dólares'): 1,\n",
       " ('dólares', 'piensan'): 1,\n",
       " ('piensan', 'adquirir'): 1,\n",
       " ('adquirir', 'créditos'): 1,\n",
       " ('créditos', 'libre'): 1,\n",
       " ('libre', 'inversión'): 2,\n",
       " ('inversión', 'expertos'): 1,\n",
       " ('expertos', 'consideran'): 1,\n",
       " ('consideran', 'medida'): 1,\n",
       " ('medida', 'peligrosa'): 1,\n",
       " ('peligrosa', 'efectivamente'): 1,\n",
       " ('efectivamente', 'comprueba'): 1,\n",
       " ('comprueba', 'datos'): 1,\n",
       " ('datos', 'adquirir'): 1,\n",
       " ('adquirir', 'deuda'): 1,\n",
       " ('deuda', 'altas'): 1,\n",
       " ('altas', 'tasas'): 1,\n",
       " ('tasas', 'moneda'): 1,\n",
       " ('moneda', 'volátil'): 1,\n",
       " ('volátil', 'resultar'): 1,\n",
       " ('resultar', 'pérdidas'): 1,\n",
       " ('pérdidas', 'operación'): 1,\n",
       " ('operación', 'arriesgada'): 1,\n",
       " ('arriesgada', 'instancia'): 1,\n",
       " ('instancia', 'préstamos'): 1,\n",
       " ('préstamos', 'libre'): 1,\n",
       " ('inversión', 'actualmente'): 1,\n",
       " ('actualmente', 'tasas'): 1,\n",
       " ('tasas', 'colocación'): 1,\n",
       " ('colocación', 'elevadas'): 1,\n",
       " ('elevadas', 'mercado'): 1,\n",
       " ('mercado', 'capital'): 1,\n",
       " ('capital', 'destina'): 1,\n",
       " ('destina', 'compra'): 1,\n",
       " ('compra', 'dólares'): 1,\n",
       " ('dólares', 'idea'): 1,\n",
       " ('idea', 'divisa'): 1,\n",
       " ('divisa', 'subir'): 1,\n",
       " ('subir', 'básicamente'): 1,\n",
       " ('básicamente', 'moneda'): 1,\n",
       " ('moneda', 'aire'): 1,\n",
       " ('aire', 'asegura'): 1,\n",
       " ('asegura', 'alexander'): 1,\n",
       " ('alexander', 'ríos'): 1,\n",
       " ('ríos', 'fundador'): 1,\n",
       " ('fundador', 'inverxia'): 1}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entidades = set(df_curated.loc[0, 'Entidades de Contenido'].split(', '))\n",
    "\n",
    "palabras = df_curated.loc[0, 'Contenido procesado'].split(', ')\n",
    "ngrams = list(nltk.ngrams(palabras, 2))\n",
    "freq_pal = dict(nltk.FreqDist(ngrams))\n",
    "freq_pal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'hola' in 'hola cómo estas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entidades = set(df_curated.loc[0, 'Entidades de Contenido'].split(', '))\n",
    "\n",
    "palabras = df_curated.loc[0, 'Contenido procesado'].split(', ')\n",
    "ngrams = list(nltk.ngrams(palabras, 2))\n",
    "freq_pal = nltk.FreqDist(ngrams)\n",
    "freq_pal = dict(nltk.FreqDist(palabras))\n",
    "\n",
    "lista = []\n",
    "for key, value in freq_pal.items():\n",
    "    if key in entidades:\n",
    "        lista.append([key, value, indice, 1])\n",
    "    else:\n",
    "        lista.append([key, value, indice, 0])\n",
    "\n",
    "return pd.DataFrame(lista, columns=['Palabra', 'Frecuencia', 'ID_Articulo', 'Entidad'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
