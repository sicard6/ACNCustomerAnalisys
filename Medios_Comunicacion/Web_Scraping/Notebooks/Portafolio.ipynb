{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from selenium.webdriver.common.by import By\n",
        "from datetime import datetime\n",
        "import selenium as sel\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import sys\n",
        "cwd = os.getcwd()\n",
        "cwd = cwd.replace(\"Notebooks\", \"Scripts\")\n",
        "sys.path.insert(0, cwd.replace(\"\\\\\\\\\", \"\\\\\"))\n",
        "import base as bs\n",
        "\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.support.ui import WebDriverWait"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Empresa con la cual vamos a extraer los articulos\n",
        "empresa = input(\"Digite la empresa a extraer: \").strip()\n",
        "if \" \" in empresa:\n",
        "    empresa_ = empresa.replace(\" \", \"%20\")\n",
        "else:\n",
        "    empresa_ = empresa\n",
        "num_paginas = int(input(\"Digite la empresa a extraer: \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# crear driver... MODIFICAR DEPENDIENDO DEL NAVEGADOR\n",
        "driver = bs.ejecutar_driver(f'https://www.portafolio.co/buscar?q={empresa_}')\n",
        "button = WebDriverWait(driver, 500)\\\n",
        "    .until(EC.element_to_be_clickable((By.XPATH,\n",
        "                                      './/button[@class=\"align-right secondary slidedown-button\"]')))\n",
        "button.click()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  5.20it/s]\n",
            "100%|██████████| 10/10 [00:02<00:00,  4.97it/s]\n",
            "100%|██████████| 10/10 [00:02<00:00,  3.85it/s]\n",
            "100%|██████████| 3/3 [00:10<00:00,  3.51s/it]\n"
          ]
        }
      ],
      "source": [
        "# Articulos a extraer\n",
        "url_princ = f'https://www.portafolio.co/buscar?q={empresa_}&page='\n",
        "titulares = []\n",
        "for i in tqdm(range(1, num_paginas+1)):\n",
        "    if i != 1:\n",
        "        aux = str(i)\n",
        "        url_a_buscar = url_princ+aux\n",
        "        driver.get(url_a_buscar)\n",
        "    articulos = [driver.find_element(By.XPATH, './/div[contains(@class, \"listing-item first \")]')] + driver.find_elements(By.XPATH, './/div[contains(@class, \"listing-item  \")]')\n",
        "    \n",
        "    for art in tqdm(articulos):\n",
        "        url = art.find_element(By.XPATH, './/h3[@class=\"listing-title\"]//a').get_attribute('href')\n",
        "        if not(bs.existedb(url, \"database\")):\n",
        "            titulo = art.find_element(By.XPATH, './/h3[@class=\"listing-title\"]//a').text\n",
        "            fechaP = bs.obtener_fecha_port(art)\n",
        "            tema = art.find_element(By.XPATH, './/div[@class=\"listing-category\"]').text\n",
        "            resumen = art.find_element(By.XPATH, './/div[@class=\"listing-epigraph\"]').text\n",
        "            imagen = bs.obtener_imagen_port(art)\n",
        "            titulares.append({'Fecha Extraccion':datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                            'Titulo': titulo,\n",
        "                            'Fecha Publicacion': fechaP,\n",
        "                            'URL': url,\n",
        "                            'Tema': tema,\n",
        "                            'Resumen': resumen,\n",
        "                            'Imagen': imagen,\n",
        "                            'Empresa': empresa,\n",
        "                            'Fuente': 'Portafolio'\n",
        "                            })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [02:06<00:00,  4.23s/it]\n"
          ]
        }
      ],
      "source": [
        "for tit in tqdm(titulares):\n",
        "    driver.get(tit[\"URL\"])\n",
        "    driver.implicitly_wait(10)\n",
        "    tit['Autor'], tit['Contenido'], tit['RelNewsUrls'] = bs.obtener_autor_contenido_relsnews(driver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(titulares)\n",
        "# bs.writeData(\"database\", df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "driver.quit()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
