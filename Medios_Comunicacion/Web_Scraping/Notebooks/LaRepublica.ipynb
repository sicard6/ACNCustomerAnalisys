{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import selenium as sel\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "cwd = cwd.replace(\"Notebooks\", \"Scripts\")\n",
    "sys.path.insert(0, cwd.replace(\"\\\\\\\\\", \"\\\\\"))\n",
    "import base as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empresa con la cual vamos a extraer los articulos\n",
    "empresa = 'ecopetrol' # input(\"Digite la empresa a extraer: \").lower().strip()\n",
    "if \" \" in empresa:\n",
    "    empresa = empresa.replace(\" \", \"%20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cerar driver... MODIFICAR DEPENDIENDO DEL NAVEGADOR\n",
    "driver = bs.ejecutar_driver(f'https://www.larepublica.co/{empresa}', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sacar primer titular CON BASE DE DATOS INICIAL\n",
    "titulares = []\n",
    "princip = driver.find_element(By.XPATH,'.//div[contains(@class,\"first-news\")]')\n",
    "urlPrinc = princip.find_elements(By.XPATH,'.//a')[1].get_attribute('href')\n",
    "if not(bs.existedb(urlPrinc,\"database\")): # Si no existe (elimine el .csv)\n",
    "    temaPrinc = princip.find_elements(By.XPATH,'.//a')[1].text\n",
    "    fechaPrinc = princip.find_element(By.XPATH,'.//span').text\n",
    "    tituloPrinc = princip.find_elements(By.XPATH,'.//a')[2].text\n",
    "    imagenPrinc = princip.find_element(By.XPATH,'.//img').get_attribute('src')\n",
    "    titulares.append({'Fecha Extraccion':datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        'Titulo':tituloPrinc,\n",
    "                        'Fecha Publicacion':fechaPrinc,\n",
    "                        'Tema':temaPrinc,\n",
    "                        'URL':urlPrinc,\n",
    "                        'Imagen':imagenPrinc,\n",
    "                        'Empresa':empresa})\n",
    "\n",
    "#el resto, autor, resumen, contenido y relacionados se sacan entrando a la url\n",
    "#despues de guardar articulos normales. Mismo para las otras dos noticias principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'driver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Extrae la lista de todos los articulos de la pagina\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m articulos \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_elements(By\u001b[39m.\u001b[39mXPATH,\u001b[39m'\u001b[39m\u001b[39m.//div[contains(@class,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrow news\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# Todas las noticias relacionadas\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'driver' is not defined"
     ]
    }
   ],
   "source": [
    "# Extrae la lista de todos los articulos de la pagina\n",
    "articulos = driver.find_elements(By.XPATH,'.//div[contains(@class,\"row news\")]') # Todas las noticias relacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itera por cada articulo y extrae la informacion (CASO DE QUE YA EXISTA ARCHIVO DONDE SE ALMACENA)\n",
    "for art in articulos:\n",
    "    url = art.find_elements(By.XPATH,'.//a')[1].get_attribute('href')\n",
    "    if not(bs.existedb(url,\"database\")): # Agregar la fuente para que corra la funci√≥n .existedb\n",
    "        fechaP = art.find_element(By.XPATH,'.//span[@class = \"date-news\"]').text\n",
    "        tema = art.find_elements(By.XPATH,'.//a')[1].text\n",
    "        resumen = art.find_element(By.XPATH,'.//p').text\n",
    "        titulo = art.find_element(By.XPATH,'.//h2').text\n",
    "        imagen = art.find_elements(By.XPATH,'.//img')[0].get_attribute('src')\n",
    "        titulares.append({'Fecha Extraccion':datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        'Titulo':titulo,\n",
    "                        'Fecha Publicacion':fechaP,\n",
    "                        'Tema':tema,\n",
    "                        'Resumen':resumen,\n",
    "                        'URL':url,\n",
    "                        'Imagen':imagen,\n",
    "                        'Empresa':empresa})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se carga la info del primer titular\n",
    "driver.get(titulares[0]['URL'])\n",
    "\n",
    "# agregar resumen al dict de titularesPrinc\n",
    "titulares[0]['Resumen'] = bs.obtener_resumen(driver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# busca los autores de cada articulo y las almacena en la lista de titulares\n",
    "for tit in titulares:\n",
    "    \n",
    "    driver.get(tit['URL'])\n",
    "\n",
    "    # agregar autor al dict de titulares\n",
    "    tit['Autor'] = bs.obtener_autor(driver)\n",
    "    \n",
    "    # agregar contenido al dict de titulares\n",
    "    tit['Contenido'] = bs.obtener_contenido_republica(driver)\n",
    "    \n",
    "    #agregar lista de URLs de noticias relacionadas\n",
    "    tit['RelNewsUrls'] = bs.obtener_articulos_relacionados(driver)     \n",
    "\n",
    "    # se podria agregar un if resumen vacio, llamar a resumen. (para las 3 noticias principales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(titulares)\n",
    "# bs.writeData(\"database\", df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
